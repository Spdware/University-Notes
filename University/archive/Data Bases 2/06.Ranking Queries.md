The idea is that we have a lot of data stored in data lakes and the objective is to extract data  and we want to extract the best result..
### Multi-objective optimization
The idea is that we have data stored in tables with attributes, features of data describing them. 
A general problem formulation:
- Given N objects described by d attributes and some notion of “goodness” of an object. Find the best k objects
If the numerical value have the possibilities to define a goodness criteria we can implement a criteria optimization. 
This problem is done each time you use a search engine, an e-commerce site,...
Classical applications:
- Multi-criteria queries: example: ranking hotels by combining criteria about available facilities, driving distance, stars, …
- k-Nearest Neighbors: given N points in some metric (d-dimensional) space, and a query point q in the same space, find the k points closest to q. Used for classification in Machine Learning
Main approaches:
- Ranking (aka top-k) queries
	- Top k objects according to a given scoring function
- Skyline queries
	- Set of non-dominated objects(not better than an object on one or more the dimension)
### Rank aggregation
Rank aggregation is the problem of combining several ranked lists of objects in a robust way to produce a single consensus ranking of the objects. If everybody express a list of preference how can we aggregate these lists in a single list?
**Borda’s and Condorcet’s proposals**
Takes in account the position of the candidate in respect of the ranking: the lower the ranking the greatest the penalty and the one with the less penalty win(Borda's idea). Condorcet winner: a candidate who defeats every other candidate in pairwise majority rule election. Condorcet's winner may not exist as there could be a cycle in the preferences.
**Approaches to rank aggregation**
Axiomatic approach
- Desiderata of aggregation formulated as “axioms”
- Arrow’s result: a small set of natural requirements cannot be simultaneously achieved by any nontrivial aggregation function
- Arrow’s paradox: no rank-order electoral system can be designed that always satisfies these "fairness" criteria:
	- No dictatorship (nobody determines, alone, the group’s preference)
	- If all prefer X to Y, then the group prefers X to Y
	- If, for all voters, the preference between X and Y is unchanged, then the group preference between X and Y is unchanged
Metric approach
- Finding a new ranking R whose total distance to the initial rankings $R_1,…, R_n$ is minimized
- Several ways to define a distance between rankings, e.g.:
- Kendall tau distance $K(R_1, R_2)$, defined as the number of exchanges in a bubble sort to convert $R_1$ to $R_2$
- Spearman’s footrule distance $F(R_1, R_2)$, which adds up the distance between the ranks of the same item in the two rankings
-  Finding an exact solution is
	- computationally hard for Kendall tau (NP-complete)
	- tractable for Spearman’s footrule (PTIME)
- These distances are related: $K(R_1, R_2) ≤ F(R_1, R_2) ≤ 2 K(R_1, R_2)$,  and $F(R_1, R_2)$ admits efficient approximations (e.g., median ranking)
### Combining opaque rankings
Techniques using only the position of the elements in the ranking (a.k.a. ranked list)
- no other associated score 
 We review MedRank:
- Based on the notion of median, it provides a(n approximation of) Footrule-optimal aggregation

![](https://i.imgur.com/prTkjAG.png)

The (maximum) number of sorted accesses made on each list is also called the depth reached by the algorithm. The higher the depth the higher the cost.
**Optimality of MedRank**
An algorithm is optimal if its execution cost is never worse than any other algorithm on any
input. MedRank is not optimal. However, it is instance-optimal. Among the algorithms that access the lists in sorted order, this is the best possible algorithm (up to a constant factor) on every input instance. In other words, its cost cannot be arbitrarily worse than any other algorithm on any problem instance.
### Definition of instance optimality
A form of optimality aimed at when standard optimality is unachievable
- Let A be a family of algorithms, I a set of problem instances
- Let cost be a cost metric applied to an algorithm-instance pair
- Algorithm A* is instance-optimal wrt. A and I for the cost metric cost if there exist constants $k_1$ and $k_2$ such that, for all A∈**A** and I∈**I**, $cost(A*, I) ≤ k_1 ⋅ cost(A, I) + k_2$
If A* is instance-optimal, then any algorithm can improve wrt A* by only a constant factor r, which is therefore called the optimality ratio of A*. Instance optimality is a much stronger notion than optimality in the average or worst case! (E.g., binary search is worst-case optimal, but not instance optimal) For each instance, a positive answer can be obtained in 1 probe, a negative answer in 2
probes (<< log N)
Example: MedRank:
- Optimality ratio = 2, additive constant = m
- If we want to can get rid of dependence on m, we get optimality ratio = 4
### Ranking queries (a.k.a. top-k queries)
Aim: to retrieve only the k best answers from a potentially (very) large result set
Best = most important/interesting/relevant/…
Useful in a variety of scenarios, such as e-commerce, scientific DB’s, Web search, multimedia systems, etc.
Needed: ability to “rank” objects (1st best, 2nd best, …)
Ranking = ordering objects based on their “relevance”
**Top-k queries: naïve approach**
Assume a scoring function S that assigns to each tuple t a numerical score for ranking tuples(E.g. S(t) = t.Points + t.Rebounds) Straightforward way to compute the result

![](https://i.imgur.com/AnufrAo.png)

Naïve approach expensive for large datasets: requires sorting a large amount of data, even worse if more than one relation is involved. S(t) = t.Points + t.Rebounds
Need to join all tuples, which is also costly. Here the join is 1-1, but in general it can be M-N (each tuple can join with an arbitrary number of tuples)
### Top-k queries in SQL
Two abilities required:
1. Ordering the tuples according to their scores
2. Limiting the output cardinality to k tuples
Ordering is taken care of by ORDER BY
Limiting was not native in SQL until 2008
	FETCH FIRST k ROWS ONLY (SQL:2008)
Supported by IBM DB2, PostgreSQL, Oracle, MS SQL Server, …
Many non-standard syntaxes available:
- ROWNUM <= k (ORACLE)
- LIMIT k (PostgreSQL, MySQL)
- SELECT TOP k FROM (MS SQL Server)
ORDER BY have limited power as can miss some relevant answers(near miss) or return too much informations(informations overload)
### Semantics of top-k queries
Only the first k tuples become part of the result
If more than one set of k tuples satisfies the ORDER BY directive, any of such sets is a valid
answer (non-deterministic semantics)
### Evaluation of top-k queries
Two basic aspects to consider:
- query type: 1 relation, many relations, aggregate results, …
- access paths: no index, indexes on all/some ranking attributes
Simplest case: top-k selection query with only 1 relation:
- If input sorted according to S: read only first k tuples. No need to scan the entire input
- Tuples not sorted: if k is not too large (which is the typical case), perform in-memory sort (through a heap). The entire input needs to be read (cost O(N log k)). Can be improved to O(N + k log N) or even O(N + k log k)
### Top-k join queries
The scoring function takes some criteria to adapt to the result of the query with all the relations it has to respect as we have n>1 input relations
Pay attention to the convention you are using, common scoring functions:
- SUM (AVG): used to weigh preferences equally, SUM(o) º SUM(p(o)) = p1(o) + p2(o) + … + pm(o)
- WSUM (Weighted sum): to weigh the ranking attributes differently, WSUM(o) º WSUM(p(o)) = w1*p1(o) + w2*p2(o) + … + wm*pm(o)
- MIN (Minimum): just considers the worst partial score, MIN(o) º MIN(p(o)) = min{p1(o),p2(o), …, pm(o)}
- MAX (Maximum): just considers the best partial score, MAX(o) º MAX(p(o)) = max{p1(o),p2(o), …, pm(o)}
