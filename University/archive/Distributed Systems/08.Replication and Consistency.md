We replicate data for increasing throughput, fault tolerance, availability(data crashes or tons of connections and DDoS attack), to improve latency(a copy closer to you will be accessible faster). We can also support disconnected operations. Desisgning for latency is something you need to do as it quickly becomes the constraint of the system.
Achieve fault tolerance
- Deal with failures / incorrect behaviors through redundancy
- We have already discussed consensus protocols for replicated state machines
	- Illusion of a single machine
Increase availability
- Data may be available only intermittently in a mobile setting
	- A local replica in the mobile node can provide support for disconnected operations
- Data might become unavailable due to excessive load
	- For example, release of a new operating system
Improve performance:
- Sharing of workload to increase the throughput of served requests and reduce the latency for individual requests
	- Example: replicate a Web server to sustain a higher number of users and reduce queuing effects for individual users
- Replicate data close to the users to reduce the latency for individual requests
	- Examples: cache in processors, local copy on mobile devices, content-delivery networks, geo-replicated datastores …
### Dealing with latency
Latency does not improve over time as others performance metrics do. As other metrics improve, latency may easily become the limiting factor for performance.

![](https://i.imgur.com/rIkDPs3.png)

We use 5 replicas to have a trade off between guarantees and loads as that is not a great number of nodes.
You also need to take in consideration the physics of the transportation of the information, latency as a limit of improvement dictated by the physical system you are using to distribute information.
### Replication: Challenges
You want the illusion of working with a single copy. Latency, communication and the protocol to communicate between nodes becomes more complicated the more consistency you want. The problem is the way to reach the level of consistency we want.
Main problem: consistency across replicas
- Changing a replica demands changes to all the others
- What happens if multiple replicas are updated concurrently?
	- Write-write conflicts / read-write conflicts
	- What is the behavior in the case of conflicts?
Goal: provide consistency with limited communication overhead
Scalability vs performance
- Replication may degrade performance!
- The cost to ensure that data is consistent across replicas can be very high
	- E.g., wait until a write has been successfully propagated to all replicas before making any progress
Different consistency requirements depending on the application scenario
- Data-centric vs client-centric
### Consistency models
We will see data store where they work on the data they store locally and update them consistently. This data have replication protocols that permit the data to remain consistent. 

![](https://i.imgur.com/Ob6VI7o.png)

A consistency model is a contract between the processes and the data store
- Stricter guarantees simplify the development but incur higher costs 
- Weaker guarantees reduce the cost but make development difficult
- Tradeoffs: guarantees, performance, ease of use
Several different models
- Guarantees on content: maximum “difference” on the versions stored at different replicas
- Guarantees on staleness: maximum time between a change and its propagation to all replicas(web browser mechanism)
- Guarantees on the order of updates: constrain the possible behaviours in the case of conflicts, data-centric vs client-centric(read the transactions from the local copy and do some assumptions on the order of operations)
### Consistency protocols
Consistency protocols implement consistency models
We first overview the main implementation strategies used in consistency protocols then we discuss consistency models in detail and show how protocols can guarantee them
- Single leader
- Multi leader
- Leaderless
#### Single leader protocols
Writes goes through the leader. The read may go through the leader
One of the replicas is designated as the leader. When clients want to write to the data store, they must send the request to the leader, which first writes the new data to its local storage
The other replicas are known as followers. Whenever the leader writes new data to its local storage, it also sends the data to all its followers
When a client wants to read from the database inn some systems, it queries the leader(replicas only used as “backup”, like in Raft). In other systems, it can query any replica either the leader or a follower.
**Type of protocol**
- Synchronous: the write operation completes after the leader has received a reply
from all the followers
- Asynchronous: the write operation completes when the new value is stored on the leader. Followers are updated asynchronously
- Semi-synchronous: the write operation completes when the leader has received a reply from at least k replicas.  k is a configuration parameter in many replicated databases (e.g., Cassandra)
Synchronous (or semi-synchronous with k followers) replication is safer
- Even if k-1 replicas fail, we still have a copy of the data
- Followers can recover from failures by asking updates to other replicas (catch-up recovery)
What happens if the leader fails?
- We can elect a new leader (failover)
- Many tricky situations depending on the specific assumptions
	- E.g., followers may not be up-to-date, network may be partitioned
To ensure safety, we need some consensus protocol (see previous lectures)
Single leader protocols with synchronous or semi-synchronous replication widely adopted in distributed databases(PostgreSQL, MySQL, Oracle, SQL Server, MongoDB)
Context: single organization / data center
- Low latency within the data center makes synchronous replication feasible
- Benefits in the case of frequent read accesses, which can be distributed across replicas
Further optimizations used in practice(E.g., partition the data and assign a different leader to each partition,to better distribute the write load)
No write-write conflicts possible:
- The leader receives all write operations and determines their order
Read-write conflicts still possible
- Depending on the specific implementation
- E.g., a client reads from an asynchronous replica and does not see writes it previously performed on the leader
#### Multi leader protocols
When the geographical area is really large we use multiple leaders protocols. They guarantee less consistency. They also can be used when the transactions are distributed geographically
Writes are carried out at different replicas concurrently
No single leader means that there is no single entity that decides the order of writes
It is possible to have write-write conflicts in which two clients update the same value almost
concurrently
- How to solve conflicts depends on the specific consistency model
- We will discuss several of them later
Multi leader protocols often adopted in geo-replicated settings
- Contacting a leader that is not physically co-located can introduce prohibitive costs
In general, more difficult to handle …
- Simultaneous writes can create conflicts
… but in practice, conflicts are rare and easy to solve in several application scenarios
- E.g., social network 
	- Writes (posts, comments) are not frequent
	- Writes for one user / group of users often performed on the same replica
	- Conflicts are not critical: concurrent comments can be stored in different orders on different replicas
Multi leader protocols natively supported in some database
- In addition to single leader protocols
Single leader protocols within a data center. Multi leader protocols across data centers.  Sometimes implemented in external tools(E.g., Tungsten replicator for MySQL, GoldenGate for Oracle)
#### Leaderless protocols
In single leader and in multi leader protocols, clients send writes to a single node. In leaderless replication, the client contacts multiple replicas to perform the writes/reads. In some implementations, a coordinator forwards operations to replicas on behalf of the client
Leaderless replication uses quorum-based protocols to avoid conflicts:
- Similar to a voting system
- We need a majority of replicas to agree on the write
- We need an agreement on the value to read
Leaderless replication used in some modern key-value / columnar stores(E.g., Amazon Dynamo, Riak, Cassandra)
We will distinguish models that can be implemented with highly available protocols and models that cannot. In this context, we say that a protocol is **highly available** if it does not require synchronous/blocking communication: if a node or a network link fails a client can still receive a reply from a correct (non-failed) replica. A model that is highly available cannot guarantee consistency as the node can continue to work with its local information. There are models that are intrisically highly available implementable and models that cannot be implemented with highly availability.
# DATA-CENTRIC CONSISTENCY MODELS
Predicate on the order in which the operations are perceived within the local copies.
Graphical convention
- One line for each process
- Operations of each process appear in temporal order
- W(x)a means that the value a is written on the data item x
- R(x)a means that the value a is read from the data item x
Ideally, we would like all operations to:
- Take place instantaneously at some point in time
- Be globally ordered according to their time of occurrence
This is not possible in a distributed system as there is no single clock available. The most we can get is similar to RAFT where we have the illusion that everything is happening in order, but we are not considering time.
Even without considering time, we need to implement (expensive) coordination protocols to ensure global order.
### Sequential consistency
The result is the same as if the operations by all processes were executed in some sequential order, and the operations by each process appear in this sequence in the order specified by its program.
Operations within a process may not be re-ordered. All processes see the same interleaving. Does not rely on time

![](https://i.imgur.com/G5x1BkJ.png)

The sequence of operations must be consistent on each process to not violate the sequential consistency.
