A stochastic process is a set of random variables $X_1, X_2,...,X_n$  that operates over the same set.
The variables have an indexes(discrete or continuous number). From the second elements the value of the second random variable is conditioned by the previous one.
$$P(X_i=a_i|X_1=a_1,...,X_{i-1}=a_{i-1})$$
Things however can be simplified a lot by considering smaller levels of correlations among the random variables. If the index is continuous, it usually corresponds to the time. The set of outcomes of the random variables can also be discrete or continuous. In performance studies, the index is usually continuous, denoting the time, and the set of outcomes is discrete, corresponding to the states of a state machine.
### Continuous Time Markov Chains(CMTC)
The special type of stochastic processes with discrete state and continuous time used in performance modelling are called Continuous Time Markov Chains. The (finite or infinite) set of outcomes for the random variables, are called states {$s_1, … , s_N$}.

![](https://i.imgur.com/3RIPxt0.png)

The system remains in a state $s_j$ for a random exponentially distributed amount of time.

![](https://i.imgur.com/ZypU6WW.png)

After that, it jumps to another state, which is also randomly chosen.

![](https://i.imgur.com/YRdM7nO.png)

Thanks to the memory-less property of the exponential distribution, Markov Chains are stochastic processes where the probability of the state at time $t_m$ depends only on the state at which the system was in a previous time $t_{m-1}$ (and the total time passed $t_m-t_{m-1}$ ) :
$$(0<t_1<t_2<...<t_{m-1}<t_m)$$
To simplify the definition, we will introduce the following notation:
$$\pi_i=Pr\{Z(t)=s_i\}$$
Usually CTMC are drawn as graphs, where nodes represent the states, and edges the possible transitions among the states. Arcs are labelled with the rate of an exponential distribution.

![](https://i.imgur.com/rDqJh0l.png)

There is a one-to-one correspondence between a State Machine with exponential transition times, and a Continuous Time Markov Chain. The idea is that each state has associated one rate.

![](https://i.imgur.com/kebFBlB.png)

Each transition from state $s_i$ to state $s_j$ has associated a rate $q_{ij}$ which corresponds to the rate of an exponential random variable. The system in state $s_i$ jumps to state $s_j$ after an exponentially distributed random amount of time with rate $q_{ij}$ . If there is no arc connecting state $s_i$ to state $s_j$, then $q_{ij} = 0$ . If there are more than one arc exiting from state $s_i$ , the system follows the evolution along the path of the event that happens first (race policy).
#### State Space
The set $\Omega = \{s_i , …\}$ of all the possible states the system can assume, is called the state space of the model.
#### Transition Rate
The transition rate $q_{ij}$ can be seen as the limit of the probability that the system performs a jump in a small time $\Delta t$ , (divided by $\Delta t$):
$$q_{ij}=\lim_{\Delta t \rightarrow 0}\frac{\text{prob("System jumps from s_i to s_j in \Delta t")}}{\Delta t}$$
If $\Delta t$ is small enough, the previous definition can be inverted:
$$\text{𝑝𝑟𝑜𝑏 “System jumps from 𝑠_𝑖 to 𝑠_𝑗 in }∆𝑡” = 𝑞_{𝑖𝑗} ∙ ∆𝑡$$
### The Chapman-Kolmogorov equation
CTMC analysis allows to compute the probability $\pi_i(t)$ that the system is in each state $s_i$ of $\Omega$ at time t. More formally, from $\pi_i(t)$ we can compute the probability $\pi_i(t+\Delta t)$ at time $t+\Delta t$ as the sum of two probabilities:
1. Being in state $s_i$ at time t and not leaving state $s_i$ in $\Delta t$
2. Being in another state $s_j$ at time t (with 𝑗 ≠ 𝑖) and jumping from state $s_j$ to state $s_i$ in $\Delta t$ (for every possible state $s_j$)

![](https://i.imgur.com/PAySGq4.png)

To simplify the equations we define $q_{ii}$ as: $q_{ii}=-\sum_{j\ne i}q_{ij}$

![](https://i.imgur.com/Ng75oQg.png)

We need to remember what the equation means.
This equation need as many terms as states. 

The terms $q_{ij}$ can be collected in a matrix Q :
$$Q=\begin{vmatrix}q_{11} & \ldots &q_{1n}\\ \vdots & \ddots &\vdots\\ q_{n1}&\ldots& q_{nn}\end{vmatrix}$$
Q is called the Infinitesimal generator.
Due to the definition of $q_{ii}$, the elements of all the rows of matrix Q must sum up to 0.
If we collect all the probabilities in a row vector p(t), the Chapman-Kolmogorov equation in matrix form becomes:
$$\frac{d\pi(t)}{dt}=\pi(t)Q$$
If we know the initial state distribution $\pi(0)$ , we can compute the probability distribution at time t of the system being in each of its states, by solving the differential equation using $\pi(0)$ as the
initial condition. This is usually addressed as the transient solution of the model.
In general, we can create the Q matrix from its graphical representation, by first enumerating the states. Each state corresponds to a row and the a column of matrix Q.
