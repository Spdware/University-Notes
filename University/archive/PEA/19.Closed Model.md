Visits in closed models are similar to open models but we need the reference station = 1(In the P matrix the reference station column will have all 0) So l is a vector with all 0 but the reference position where there is 1
### Express performance matrix for closed models
in open models we used a trick: $A_k = N_k$. Since $R_k=(1+A_k)D_k=(1+\lambda R_k)D_k \Rightarrow R_k=\frac{D_k}{1-U_k}$
But in closed models this is no longer true as the number of jobs that arrive isn't equal to the jobs that left the system.
The number of jobs at arrival in closed models can be expressed through the "Arrival Theorem":
$$A_k(N)=N_k(N-1)$$
We can represent the Residence time of the system(With N jobs in the system) as:
$$R_k(N) = (1+A_k(N))D_k=(1+N_k(N-1))D_k$$
Suppose we know $N_k(N-1)$ we can compute the response time:
$$R(N)=\sum R_k(N),\text{ }X(N)=\frac{N}{R_k(N)}$$
Using Little's law, the queue length of each station can finally be determined.
$$ğ‘_ğ‘˜ ğ‘ = ğ‘‹ ğ‘ ğ‘…_ğ‘˜ (ğ‘)$$
The algorithm can then increase the population to N+1 jobs, since for the arrival theorem we have that $A_k(N+1) = N_k(N)$, and the process can be repeated.
$$ğ´_ğ‘˜ ğ‘ + 1 = ğ‘_ğ‘˜ ğ‘$$
$$R _ğ‘˜( ğ‘ + 1) = (1 + ğ´_ğ‘˜ (ğ‘ + 1)) ğ·_ğ‘˜ = 1 + ğ‘_ğ‘˜ ğ‘ ğ·_ğ‘˜$$
#### Response time law
In time-sharing systems, the "think time" is usually not considered in the system response time.
$$\begin{array}{ll}R_{tot}=R_{sys}+Z & N=XR_{tot} & N=X(R_{sys} + Z)\end{array}$$
In particular, Little's law becomes the so-called "Response Time Law" which explicitly excludes the think time from the total response time of the system computed in the usual way.
The Response Time Law is:
$$R=\frac{N}{X}-Z$$
### Separable Models
![](https://i.imgur.com/tBYxFBc.png)

We consider for both service and arrival process:
- Exponential (c.v. = 1)
- Erlang, with c.v. = 0.5
- Hyper-Exponential, with c.v. = 2
Kingsman Formula considers FCFS

![](https://i.imgur.com/XJEECT8.png)

Also no difference in both FCFS and LCFS have same Average Response TIme
It has been discovered that the analytical results such the one presented for Open and Closed networks, are valid for a large variety of systems.
In particular, the techniques e can be applied if a system is a separable queuing network.
A queueing network is separable if it fulfills five main properties.
In the following, we will present the properties directly from the book Quantitative System Performance by E. D. Lazoswka.
#### First assumptions: service center flow balance
$$A_k(T) = C_k(T)$$
This is always true in stable system when there aren't losses. System with losses cannot be separate.
#### Second assumption
Two jobs cannot change the state at the same time in the same time. Real systems almost certainly display one step behaviour(even for milliseconds)
#### Third assumption: Routing omogeneity
If there is not dependency on the routing on the left of the queue the system can have routing omogeneity and can be separable
Of the routing policies we have seen, the probabilistic routing fully satisfies the previous assumption.
Other routing policies, such as Join the Shortest Queue (JSQ) clearly violate this constraint since the decision of the next station
depends on the whole state of the system.
The previous assumption has a very big implication: as long as nodes have the same demands, two queuing networks have the same performance, independently of their topology.
#### Fourth assumption:
Device homogeneity. Tricky and important assumption
#### Fifth assumption:
Homogeneous external arrivals

These assumptions are strict but almost always valid for computer systems.