Cryptography: The study of techniques to allow secure communication and data storage in presence of attackers. 
Features provided:
- Confidentiality: data can be accessed only by chosen entities
- Integrity/freshness: detect/prevent tampering or replays
- Authenticity: data and their origin are certified
- Non-repudiation: data creator cannot repudiate created data
- Advanced features: proofs of knowledge/computation
Proof of Computation: a lot of computation used as proof of authenticity and paternity of a file. 
# History
Cryptography started as commercial confidentiality, then as war confidentiality. Initially it is designed for human computer and the algorithms were computed by hands. 
 A battle of wits between cryptographers(ideate a secret method to obfuscate a text) and cryptanalysts(figure out the method, break the “cipher”).
 Bellaso (1553) separates the encryption method from the key.
 This is a good intuition and is still used in some part in modern cryptography.
 **1883 - Kerchoff’s six principles for a good cipher (apparatus)**
1. It must be practically, if not mathematically, unbreakable
2. It should be possible to make it public, even to the enemy
3. The key must be communicable without written notes and changeable whenever the correspondants want
4. It must be applicable to telegraphic communication
5. It must be portable, and should be operable by a single person
6. Finally, given the operating environment, it should be easy to use, it shouldn’t impose excessive mental load, nor require a large set of rules to be known
The Solitaire is a good manual cipher and translator.
**The advent of the machines**
Mechanical computation changes cryptography
- First rotor machine in 1917 by Ed Hebern
- Design “popularized” in WWII by German Enigma
Cryptanalysist at Bletchley park (Turing among them) credited for a decisive effort in winning the war by Eisenhower. It worked scrambling letters around and using cables to do so moving around a rotor.
**An end to the battle of wits**
Shannon (1949) - Proves that a mathematically unbreakable cipher exists
Nash (1955) - Argues that computationally secure ciphers are ok
- Considers a cipher with a finite, λ bit long, key
- Conjecture: if “parts of the key interact complexly [...] in the determination of their effects on the cipher text”, the attacker effort to break the cipher would be $O(2^λ)$
- The owner of the key takes $O(λ^2)$ to compute the cipher
- The computational gap is unsurmountable for large λ
# Cryptography
 Randomness (in this course) characterizes a generative process. Stating: “00101 is a random string” actually makes little sense. The randomness is not from the object itself but on the process used to obtain the object itself.
 **Definitions**
 Data:  
 - Plaintext space **P**: set of possible messages ptx ∈ **P**
	Old times: words in some human-readable alphabet, modern times $\{0, 1\}^l$ 
- Ciphertext space **C**: set of possible ciphertext ctx ∈ **C**
	Usually $\{0, 1\}^{l'}$  , not necessarily l = l'  (ciphertexts may be larger)
- Key space **K**: set of possible keys
	$\{0, 1\}^λ$ , keys with special formats are derived from bitstrings
Functions:
- Encryption function E : P × K → C
- Decryption function D : C × K → P
	Correctness: for all ptx ∈ P, we need k, k'  ∈ K s.t. D(E(ptx, k), k') = ptx

![](https://i.imgur.com/fwMXyBL.png)

It is usually a pair function where we have the encryption and decryption part. The pair of the functions can be called a cipher.
## Providing confidentiality
Goal
- Prevent anyone not authorized from being able to understand data
Possible attacker models:
- The attacker simply eavesdrops (ciphertext only attack, the attacker doesn't know the key). It is very basic as an attack
- The attacker knows a set of possible plaintexts. Seems weird, but if you think about maintenance messages they can be known. These give an help to understand the complete alphabet.  
- Limit case: the attacker chooses the set of plaintexts
- The attacker may tamper with the data and observe the reactions of a decryption-capable entity. The attacker tries to know the keys.
	Limit case: the attacker sees the actual decrypted value. The attacker should not be able to ask the decryption of my message but anything else is fine. 
## Perfectly secure cipher
 In a perfect cipher, for all ptx ∈ P and ctx ∈ C, 
 Pr(ptx sent = ptx) = Pr(ptx sent = ptx | ctx sent = ctx)
In other words: seeing a ciphertext c ∈ C gives us no information on what the plaintext corresponding to c could be. It is giving me no knowledge, I have to do a random guess. So we need to build a cipher that when I see ciphertext the best way to resolve it is to throw a random dice.
Any symmetric cipher $⟨P, K, C, E, D⟩$  with |P| = |K| = |C| is perfectly secure if and
only if:
- every key is used with probability $\frac{1}{|K|}$
- a unique key maps a given plaintext into a given ciphertext:
	∀(ptx, ctx) ∈ P × C, ∃!k ∈ K s.t. E(ptx, k) = ctx
The other part needs the key to cipher the ciphertext, how it obtain the key needs to be defined.
## Perfectly secure != perfectly usable
The perfect cipher needs to send the key to the other end of the line. Need to prepare in advance as many key material as many material you send. If security was paramount the perfect cipher can be employed more freely. 
Problem can come from key theft/reuse, spies that copies these keys on paper. 
Another problem is generating random keys as humans are horrible in generating randomness. Good dice are a good way to generate randomness. 
## Computationally secure cryptography
A more practical assumption:
Build a cipher so that a successful attack is also able to solve a hard computational problem efficiently
- Solve a generic nonlinear Boolean simultaneous equation set
- Factor large integers / find discrete logarithms
- Decode a random code/find shortest lattice vector
### Proving computational security
Outline of the method:
1. Define the ideal attacker behaviour
2. Assume a given computational problem is hard
3. Prove that any non ideal attacker solves the hard problem
How to represent attacker and properties?
- Attacker represented as a program able to call given libraries
- Libraries implement the cipher at hand
- Define the security property as answering to a given question
- The attacker wins the game if it breaks the security property more often than what is possible through a random guess
## Cryptographically Safe Pseudorandom Number Generators
 We want to use a finite-length key and a Vernam cipher:
- We somehow need to “expand” the key
- We assume that the attacker can only perform poly(λ) computations
Definition
A CSPRNG is a deterministic function PRNG: $\{0, 1\}^λ$ → $\{0, 1\}^{λ+l}$ whose output cannot be distinguished from an uniform random sampling of $\{0, 1\}^{λ+l}$ in O(poly(λ)). l is the CSPRNG stretch.
 In practice, we have only candidate CSPRNGs
- We have no proof that a function prng exists
- Proving that a CSPRNG exists implies directly $P\ne NP$
Practical constructions:
- Building a CSPRNG “from scratch” is possible, but it is not the way they are commonly built (not efficient)
- Practically built with another building block: PseudoRandom Permutations (PRPs)
	 defined starting from PseudoRandom Functions (PRFs)
We have really efficient pseudo-random generator with the fact that in polynomial time you cannot rebuild the input or assume anything other than that I rolled dice at the start of the computation.
It is useful to mimic a true random stream as it can only have exponential streams, but without exponential amount of time it is impossible to test all the possible streams.
We don't design CSPRNG as a single block, it is a multitude of simple functions. We need to define a block that is Pseudorandom generator.
### Random Functions (RFs)
Randomly drawing a function:
-  Consider the set $F = \{f : \{0, 1\}^{in} → \{0, 1\}^{out} ; in, out ∈ N\}$
- A uniformly randomly sampled $f \xleftarrow{\$}F$ can be encoded by a $2^{in}$ entries table, each entry out bit wide. $|F| = (2^{out} )^{2^{in}}$
Boolean functions are a set of tables. 
**Toy example in = 2, out = 1**
$F = \{f : \{0, 1\}^2 → \{0, 1\}^1 \}$ is the set of the 16 Boolean functions w/ two inputs
Each one is represented by a 4-entry truth table
Intuitively, the functions are 16 as there are $2^4 = 16 = (2^1 )^{2^2}$ tables
### Pseudorandom Functions(PRFs)
**Definition**
- A function $prf_{seed} : \{0, 1\}^{in} → \{0, 1\}^{out}$ taking an input and a λ bits seed.
- The entire $prf_{seed}$ is described by the value of the seed 
- It cannot be told apart from a random $f ∈ \{f : \{0, 1\}^{in} → \{0, 1\}^{out} \}$ in poly(λ)
- That is, if they give you a ∈ {f : $\{0, 1\}^{in} → \{0, 1\}^{out}$ }, you can’t tell which one of the following is true 
	- a = $prf_{seed} (·)$ with seed$\xleftarrow{\$} \{0, 1\}^λ$
	- $b \xleftarrow{\$} F$, where $F = \{f : \{0, 1\}^{in} → \{0, 1\}^{out} \}$

![](https://i.imgur.com/tZYcURe.png)

### Pseudorandom Permutations (PRPs)
![](https://i.imgur.com/hEpCpnY.png)

 **Definition:**
 A bijective PRF: $prf_{seed} : \{0, 1\}^{len} → \{0, 1\}^{len}$
It is uniquely identified by the value of the seed
It is not possible to tell apart in poly(λ) from a RF
It’s a permutation of all the possible $\{0, 1\}^{len}$ strings
Operatively speaking:
- acts on a block of bits outputs another one of the same size
- the output “looks unrelated” to the input
- its action is fully identified by the seed
- Useful to think of the seed as a key
It is a permutation along all strings, if you have len bits you have $(2^{len})!$ possible permutations.
What the PRP does is having the two set of strings it knows how to draw the arrows connecting the inputs to the outputs. 
The idea is the design is good if given a box having $2^{len}$ in and have $2^{len}$ out and you cannot tell the input and the output apart. Bruteforce is not an option because we made so that is not practical.
The seed is a key that let us know how to map the inputs to the outputs.
This is the first element that we can build.
#### Real world PRPs
The first thing to do is to build the pseudorandom function.
**The issue**
- No formally proven PRP exists, yet
- again, its existence would imply $P\ne NP$
Typical construction:
1. Compute a small bijective Boolean function f of input and key
2. Compute f again between the previous output and the key
3. Repeat 2 until you’re satisfied
You can design this taking a boolean function with a great bias an see when the bias diminish and when the bias is under a threshold you can stop as you found the function you want. Design a small function and apply it multiple time.
In the real world we have Block Cipher, the seed is the key of the cipher.
**Practical solution: public scrutiny**
- Modern PRPs are the outcome of public contests
- Cryptanalytic techniques provide ways (=poly(λ) tests) to detect biases in their outputs: good designs are immune
**PRPs a.k.a. Block ciphers**
- Concrete PRPs go by the historical name of block ciphers
- Considered broken if, with less than $2^λ$ operations, they can be told apart from a PRP, e.g., via:
	- Deriving the input corresponding to an output without the key
	- Deriving the key identifying the PRP, or reducing the amount of plausible ones
	- Identifying non-uniformities in their outputs
The key length λ is chosen to be large enough so that computing $2^λ$ guesses is not practically feasible
All cipher are immune to statistical text and cannot have foreseen, there is random draw. Difficult to cut through real deployed cipher.
## Quantifying computational unfeasibility
We need to understand how much expensive is to break through something. We can do it measuring it in energy spent. Still needs to be converted in an unit that is understandable. We can use as measure the quantity of water to boil(from 20 degree Celsius). 
- $2^{65}$ op.s ≈ an Olympic swimming pool
- $2^{80}$ op.s ≈ the annual rainfall on the Netherlands
- $2^{114}$ op.s ≈ all water on Earth
Practically acceptable unfeasibility:
- Legacy level security: at least $2^{80}$ Boolean operations. Maybe not breakable but better not use them
- 5 to 10 years security: at least $2^{128}$ Boolean operations
- Long term security: at least $2^{256}$ Boolean operations
## Widespread block ciphers
Advanced Encryption Standard (AES)
- 128 bit block, three key lengths: 128, 192 and 256 bits, designed to have these three key length
- Selected after a 3 years public contest in 2000-10-2 by NIST out of 15 candidates, re-standardized by ISO/IEC. This means that is a 3 years long barfight between academicitians.
- ARMv8 and AMD64 include dedicated instructions accelerating its computation (hitting 3+ GB/s)
Data Encryption Algorithm (DEA, a.k.a. DES)
- Legacy standard by NIST (1977), the key is too short (56b)
- Patch via triple encryption, λ = 112 equivalent security
- Still found in some legacy systems, officially deprecated
First standardization of a cipher, used by USA but it is too short for standard use by now. This has been patched by incrypting with three different keys from three different groups.  
## An Electronic CodeBook (ECB)
![](https://i.imgur.com/feCqjPN.png)

A first attempt to encryption with PRPs:
- It’s ok to encrypt a plaintext ⩽ block size with a block cipher
- An extension to multiple blocks could be split-and-encrypt
	- Is it good (equivalent to Vernam fed with a CSPRNG)?
This is not a good idea as we have the same encryption for the same plaintext and we are maintaining redundancy in the plaintext. Can know when we have ping and echo replies, or worst we have images as we can see where the contour are as we can see where the colours change, even with nude eye.
### Counter (CTR) mode
Getting it right
- The boxed construction is provably a PRNG if Enc is a PRP
- There is nothing special in the starting point of the counters

![](https://i.imgur.com/jXrIQS7.png)

We can use a counter to create the encryption as it will never repeat and then do a XOR operation to add it to our plaintext creating our cipertext without repetition.
We can tell apart the various output of the block in $2^{\lambda /2}$ because we are using a pseudorandom function to do the encryption.
Every now and then change the key/function to avoid this problem, that is not a problem in practice.
## Raising the requirements
Confidentiality achieved ... for CoA
- Up to now, the attacker knew only ciphertext material
Confidentiality against Chosen Plaintext Attacks (CPAs)
- Our attacker knows a set of plaintexts which can be encrypted
- He wants to understand which one is being encrypted
- Ideal attacker: cannot tell which plaintext was encrypted out of two he chose (having the same length)
- Feels strange, but it happens with:
	- management data packets in network protocols (e.g., ICMP)
	- telling apart a encrypted commands to a remote host
With an active attacker we have the problem that it can ask for the start of the counter/for a message he knows and the attacker can deduct the cipher and start reading all the messages.
A deterministic machine is not CPA secure, we need to either add true randomness to the scheme and fix the problem. We can add public randomness in 2 way:
- Modify the scheme
- Disclose the starting point of the counter. This is the simplest way and can be communicated in clear to the other part. This is good because even if you ask the same thing you will receive a different encrypted message. Only problem is the fact that you will require an extra block(at most 16 bit, so no problem)
### Achieving CPA Security
No deterministic encryption
- The CTR mode of operation is insecure against CPA
	- The encryption is deterministic: same ptxs → same ctx
Decryptable nondeterministic encryption
1. Rekeying: change the key for each block with a ratchet
2. Randomize the encryption: add (removable) randomness to the encryption (change mode of employing PRP)
3. Numbers used ONCE (NONCEs): in the CTR case, pick a NONCE as the counter starting point. NONCE is public
I can also use a random starting point for the counter and send it before the message and encrypt from it. Doing so the attacker can be lucky to find an overlap, still needs a large counter otherwise the overlapping is too possible(only way to use counternode). Only problem is that the ciphertext is way longer than the plaintext.
If you cannot afford to have another block of data to send you cna randomize the key or the encryption.
#### Symmetric ratcheting
Getting it right
- The construction takes the name from the mechanical component: it is not possible to roll-back the procedure once you delete the value carried by green arrows

![](https://i.imgur.com/zFqtEDe.png)

We have a generator that cannot be read back in time. At each passage erase all the previous material. More expensive as we are using a PRNG and then the encryption using a new counter at each step, but provide forward security. Three times more expensive. Useful because you cannot derive the key used.  
This generate an almost never ending stream of keys.
With this scheme we don't need to store the previous message with the keys, after the message is sent the sender cannot  decrypt it, if the receiver also delete the message after it is used the message cannot be decrypted anymore. 
This is end to end encryption(no one apart from sender and receiver knows the keys, all in between is functional transfer, the channel only need to be reliable). 
### CPA-Secure Counter (CTR) mode
Getting it right:
- Picking the counter start as a NONCE generates different bitstreams to be xor-ed with the ptx each time
- The same plaintext encrypted twice is turned into two different, random-looking, ciphertexts

![](https://i.imgur.com/kJqzZiA.png)

## Malleability and active attackers
Malleability
- Making changes to the ciphertext (not knowing the key) maps to predictable changes in the plaintext
- Think about AES-CTR and AES-ECB
- Can be creatively abused to build decryption attacks
- Can be turned into a feature (homomorphic encryption)
How to avoid malleability
- Design an intrinsically non malleable scheme (non trivial)
- Add a mechanism ensuring data integrity (against attackers)
Sometimes the attacker doesn't need to know the content of the message. Active attacker mine the integrity of the message.
CTR helps with the integrity as if a block is dropped this will be evident in the reading of the message. If we flip a bit in the ciphertext(XOR with one). This can mean that we will flip a bit also in the plaintext when I am decrypting the text. CTR by erasure doesn't protect the integritiy of the message.
### Providing data integrity
**Confidentiality doesn't imply Integrity**
- Up to now our encryption schemes provide confidentiality
- Changes in the ciphertext are undetected (at best)
Message Authentication Codes (MAC)
- Add a small piece of information (tag) allowing us to test for the message integrity of the encrypted message itself
- Adding it to the plaintext and then encrypting is not good
- Nomenclature misleads: MACs do not provide data authentication
- They are also called MIC(Messages Integrity Code)
You can provide integrity to a physical object with a sticker that the receiver knows the shape/constitution. I want a similar behaviour for the message, I want to append a small amount of bit to the message. 
### MACs
**Definition**
A MAC is constituted by a pair of functions:
- compute tag(string,key): returns the tag for the input string
- verify tag(string,tag,key): returns true or false
Ideal attacker model:
- knows as many message-tag pairs as he wants
- cannot forge a valid tag for a message for which he does not know it already
- forgery also includes tag splicing from valid messages
N.B. the tag creating entity and the verifying entity must both know the same secret key
- The tag verifier is able to create a valid tag too
- ... and there goes the non-repudiation property
We wants a string that only the sender and receiver knows. This is the most efficient way to do it, but it needs to share secret information between sender and receiver. 
An attacker cannot produce a tag for a message he never seen without an authentication tag. Also should not be possible to detach a tag from a message and attach it to another message. 
### How to build a MAC? the CBC-MAC
Building a MAC with a PRP (block cipher)
- The CBC-MAC is secure for prefix free messages (why?)
- Encrypting the tag once more fixes (provably) the issue
Should look enough random if I don't know the key.

![](https://i.imgur.com/KTi89uJ.png)

The tag will depend on all the plaintext and depends on the key as it will be derived from the decryption. 
This is vulnerable on a type of attack. The attacker can know something if the message is prefix free. If I use the previous tag as the next plaintext I will encrypt a set of zeros producing the encryption of a set of zeros giving out my method for encryption. 
The fix to this is simple. If the attacker doesn't know what is outputted to the cipherrow we are good. So we can encrypt the tag another time. 
This is so secure that is standardized(CMAC).
There are faster way to do this trick, but there is the need to have an encryption before the output of the tag, all the previous encryption can be good functions with data dependencies. The choice is done regarding the needs of the system.
### Practical MAC uses
Browser cookies
- HTTP cookies are a “note to self” for the HTTP server. The server can calculate a tag on the cookie to know that the user is the right one. It is useful because it's not required to send the key as only the server needs to know it.
- The note should not be tampered between server reads
- Solution: server runs compute tag(cookie,k) and stores both the (cookie,tag)
If the message is really long verifying it could takes some time. To cope with this inefficiency you can search a way to compress the message to some bytes we can decipher this small amount of bytes(Shannon limit).
#### Compressing for the sake of efficiency
Testing integrity
- Testing the integrity of a file requires us to compare it bit by bit with an intact copy or read it entirely to compute a MAC
- It would be fantastic to test only short, fixed length strings independently from the file size, representing the file itself
- Major roadblock: there is a lower bound to the number of bits to encode a given content without information loss
## Cryptographic hashes
A pseudo-unique labeling function:
A cryptographic hash is a function $H : \{0, 1\}^∗ → \{0, 1\}^l$ for which the following problems are computationally hard
1. given d = H(s) find s (1st preimage)
2. given s, d = H(s) find $r \ne s$ with H(r) = d (2nd preimage)
3. find r , s; $r \ne s$, with H(s) = H(r) (collision)
Ideal behaviour of a concrete cryptographic hash:
1. finding 1st preimage takes $O(2^d )$ hash computations guessing s
2. finding 2nd preimage takes $O(2^d )$ hash comp.s guessing r
3. finding a collision takes ≈ $O(2^\frac{d}{2}$ ) hash computations
The output bitstring of a hash is known as a **digest**
Should not be computationally possible to find a collision, the hash algorithm is public. Anyone can compute the hash. The security margin is the fact that the function cannot be invertible solvable so the best approach is random guesses.
To break number 3 in the ideal behaviour only break number 3, the security margin is based on the size of the codomain(digest length).
As 50% to have a collision is bad enough so having $\sqrt{2^{digest_length}}= 2^{\frac{d}{2}}$ 
## Concrete hash functions
What to use:
- SHA-2(Secure Hash Algorithm 2) was privately designed (NSA), d ∈ {256, 384, 512}(This is done to have the same security as cipher)
- SHA-3 followed a public design contest (similar to AES), selected among ≈ 60 candidates, d ∈ {256, 384, 512}
- Both currently unbroken and widely standardized (NIST, ISO)
What not to use
- SHA-1: d = 160, collision-broken [6] (obtainable in ≈ 261 op.s)
- MD-5: horribly broken [7]. Collisions in 211 , public tools online [5]
	- In particular, collisions with arbitrary input prefixes in ≈ 240
### Uses for hash functions
Pseudonymized match
- Store/compare hashes instead of values (e.g., Signal contact discovery) 
MACs
- Building MACs: generate tag hashing together the message and a secret string, verify tag recomputing the same hash
- A field-proven way of combining message and secret is HMAC
- Standardized (RFC 2104, NIST FIPS 198)
- Uses a generic hash function as a plug-in, combination denoted as HMAC-hash name
- HMAC-SHA1 (!), HMAC-SHA2 and HMAC-SHA3 are ok
Forensic use
- Write down only the hash of the disk image you obtained in official documents A. Barenghi
### Game changing ideas
Features we would like to have
- Agreeing on a short secret over a public channel
- Confidentially sending a message over a public authenticated channel without sharing a secret with the recipient
- Actual data authentication
**Solution: asymmetric cryptosystems**
- Before 1976: rely on human carriers / physical signatures
- DH key agreement (1976) / Public key encryption (1977)
- Digital signatures (1977)
### A cautionary note on security margins
Computational hardness
- Up to now, enumeration of the secret parameter was the best possible attack
- This is ok for modern block ciphers → best attack: $O(2^λ)$
- Asymmetric cryptosystems rely on hard problems for which bruteforcing the secret parameter is not the best attack
	 Factoring a λ bit number takes $O(e^{k(λ)^{\frac{1}{3}}(log(λ))^{\frac{2}{3}}})$
- Comparing bit-sizes of the security parameters instead of actual complexities is really wrong
- Concrete bit-sizes for λ depending on the cipher: www.keylength.org
You need to match the security level of asymmetric and symmetric values of keys.
## The Diffie-Hellman key agreement
Goal
- Make two parties share secret value w/ only public messages
Attacker model
- Can eavesdrop anything, but not tamper
- The Computational Diffie-Hellman assumption should hold
CDH Assumption
- Let $(G, ·) ≡ \langle g \rangle$ be a finite cyclic group, and two numbers a, b sampled unif. from {0, . . . , |G| − 1} (λ = len(a) ≈ $log_2$ |G|)
- given $g^a$ , $g^b$ finding $g^{ab}$ costs more than poly(log |G|)
- Best current attack approach: find either b or a (discrete log problem)
The idea is the attacker is only passive and there is a problem computationally hard.
### Structure
Key agreement between Alice and Bob:
- Alice: picks a $\xleftarrow{\$}$ {0, . . . , |G| − 1}, sends $g^a$ to Bob
- Bob: picks b $\xleftarrow{\$}$  {0, . . . , |G| − 1}, sends $g^b$ to Alice
- Alice: gets $g^b$ from Bob and computes $(g^b)^a$
- Bob: gets g a from Bob and computes $(g^a)^b$
- (G, ·) is commutative → $(g^b)^a$ = $(g^a)^b$ , we’re done!
Groups used in practice:
- A subgroup (G, ·) of $(Z_n^∗, ·)$ (integers mod _n_),  breaking CDH takes$$min(O(e^{k(n)^{\frac{1}{3}}(log(n))^{\frac{2}{3}}}) , O(2^{\frac{λ}{2}}))$$
- EC points w/ dedicated addition, breaking CDH takes $O(2^\frac{λ}{2})$
## Public Key Encryption
Components
- Different keys are employed in encryption/decryption
- It is computationally hard to:
	- Decrypt a ciphertext without the private key
	- Compute the private key given only the public key

![](https://i.imgur.com/frS29md.png)

Encryption key is public as you cannot obtain the decryption key, so it is safe even if the encryption key is know to anyone that search it. It is **IMPERATIVE** that the decryption key remain private or the system will be useless.
Public key is like a safe and the private key is the combination.
## Widespread Asymmetric encryption ciphers
Rivest, Shamir, Adleman (RSA), 1977
- 2048 to 4096 bit message-and key-sizes
- Patented after the invention, patent now expired
- No ciphertext expansion
- Incidentally, the encryption with a fixed key is a PRP
Elgamal encryption scheme, 1985
- Either kbit range keys, or 100’s of bits keys, depending on the variant
- Not encumbered by patents
- The ciphertext is twice the size of the plaintext
- Widely used as an RSA alternative where patents were a concern
## Key Encapsulation
Assumption
- A public channel between Alice and Bob is available
- For the moment, the attacker model is “eavesdrop only”
Sharing a secret without agreement
- Alice: generates a keypair $(k_{pri} , k_{pub} )$, sends to Bob
- Bob: gets s $\xleftarrow{\$}$ $\{0, 1\}^λ$ , encrypts it with $k_{pub}$ , sends ctx to Alice
- Alice: decrypts ctx with $k_{pri}$ , recovers s
- Note: Bob alone decides the value of the shared secret s
	- Repeat the procedure with swapped roles and combine the two secrets to achieve similar guarantees to a key agreement
We want to share a key without using another one to encrypt it. 
It is the way to transmit the key of a cipher to another user using a public channel.
Doing  so only one user decide the symmetric part of the algorithm. 
### Efficiency considerations
 Employing an asymmetric cryptosystem Bob encrypts a text for Alice without the need of sharing a secret beforehand
In principle, Bob and Alice could employ only an asymmetric cryptosystem to communicate
In practice this approach would be extremely inefficient
- Asymmetric cryptosystems are from 10× to 1000× slower than their symmetric counterparts
As the cipher works in nanoseconds meanwhile this mechanism works in microseconds.
We encrypt a symmetric key with the idea of using both symmetric and asymmetric cipher to have both efficiency and speed.

![](https://i.imgur.com/yjVCSeS.png)

Hybrid encryption schemes:
- Asymmetric schemes to provide key transport/agreement
- Symmetric schemes to encrypt the bulk of the data
- All modern secure transport protocols built around this idea
Using this and generating a fresh key the asymmetric cipher can be suboptimal because you are using a new key at each message. This DOES NOT provide integrity, you need to add a MAC for this(can split the key for the MAC and for the encryption, doing so needs to encapsulate two keys.)
## Authenticating data
Motivations
- To build a secure hybrid encryption scheme we need to be sure that the public key the sender uses is the one of the recipient
- We’d like to be able to verify the authenticity of a piece of data without a pre-shared secret
Digital signatures
- Provide strong evidence that data is bound to a specific user
- No shared secret is needed to check (validate) the signature
- Proper signatures cannot be repudiated by the user
- They are asymmetric cryptographic algorithms
	- formally proven that you cannot get non repudiation otherwise
The secret signing key is on a side the public verification key is on another side. If another guy can authenticate something you can do it too.
We want that only the signer can mark an object and everyone can see who marked the object(no repudiation if the key is not stolen, legally binding similar to signing a paper with a notary).

![](https://i.imgur.com/S1OO8Mh.png)

Computationally hard problems
- Sign a message without the signature key
	- this includes splicing signatures from other messages
- Compute the signature key given only the verification key
- Derive the signature key from signed messages
I have a block that sign and a block that verify. The first algorithm used RSA because of its intrinsic symmetry(only object that can be used in both). DO NOT USE something used for encryption for signature and vice versa.
## Widespread Signature schemes
Rivest, Shamir, Adleman (RSA), 1977
- Unique case: the same hard-to-invert function to build an asymmetric encryption scheme and a signature (different message processing!)
- Signing definitely slower than verification (≈ 300×)
- Standardized in NIST DSS (FIPS-184-4)
Digital Signature Standard (DSA)
- Derived from tweaking signature schemes by Schnorr and Elgamal
- Also standardized in NIST DSS (FIPS-184-4)
- Signature and verification take roughly the same time
Signature is almost 300 times slower than verifying(17 multiplication to verify something, can done with the bootloader).
The alternated scheme(DSA) is standardized after some tweaks. The last tweak added something that is really complex(this introduced the problem that creating a botched signature is easier than creating a correct one). DSA doesn't need the scrutinizing, signature doesn't contain information on the hierarchy. Need to draw fresh random number each time, otherwise you can find the complete signature key.
RSA signature is slower than the DSA, but is more secure on the fact that is simpler to implement a correct one.
## Digital signature uses
Authenticating digital documents
- For performance reasons, sign the hash of the document instead of the document
- Signature properties now guaranteed only if both signature and hash algorithms are not broken
Authenticating users
- Alternative to password-based login to a system
	- The server has the user’s public verification key (e.g. deposited at account creation)
	- The server asks the client to sign a long randomly generated bitstring (challenge)
	- If the client returns a correctly signed challenge, it has proven its identity to the server

## The public key binding problem
Cautionary note
- Both in asymmetric encryption and digital signatures, the public key must be bound to the correct user identity
- If public keys are not authentic:
	- A MITM attack is possible on asymmetric encryption
	- Anyone can produce a signature on behalf of anyone else
- The public key authenticity is guaranteed with... another signature
	- We need someone to sign the public-key/identity pair
	- We need a format to distribute signed pairs
We want to mitigate the number of key needed before blindly trusting public keys to resolve the signature. Need of validating the signature. We say that our public key is signed by someone with bigger authority.
## Digital certificates
Digital certificates
- They bind a public key to a given identity, which is:
	- for humans: an ASCII string
	- for machines: either the CNAME or IP address
- They specify the intended use for the public key contained
	• Avoids ambiguities when a key format is ok for both an encryption and a signature algorithm
- They contain a time interval in which they are valid
- Most widely deployed format is described in ITU X.509
Digital certificate will contain an identity, or name(for servers) and we need to bound the public certification key to this identity. Typically they contain other information such as expiration dates(private signing key can be breached), starting date(if certificate expires for a second the system will not works and needs an overlap in invalidity to have the system always up and having two certificate to let the first one expire safely).
## Certification authorities
Who signs the certificates
- The certificate signer is a trusted third party, the CA
 - The CA public key is authenticated... with another certificate
- Up to a self-signed certificate which has to be trusted a priori

![](https://i.imgur.com/KB4ZWB2.png)
![](https://i.imgur.com/XzLRolz.png)

- Subject: the one that wants the key to be certificated
- Issuer: the one that certificate the key
- Signature: signature needed to certificate the document
The last certificate in the chain is self certificated, this is done because we trust that it will not be tampered. This helps as I have to trust only one certificate and not everything.
Nowadays we have a hierarchy at multiple levels with a root certification authorities and the Subsidiary CA that let you certificate multiple certificate and use the key to verify some certificates.
## Putting it all together
![](https://i.imgur.com/vKZ8i5Q.png)

All of this is user transparent.
## Directions in modern cryptography
Issues to solve, features to realize
- What if we have a quantum computer?
	 Some computationally hard problems are no longer hard
	 Move away from cryptosystems based on factoring/dlog
	 Alternatives available and being standardized (2022-04)
- What if we want to compute on encrypted data?
	 Yes, but it’s moderately-to-horribly inefficient
- What if the attacker has physical access to the device computing the cipher (or some way of remotely measure it)
	 Take into account **side channel** information in the attacker model
There are scheme for confidential computation.
There are also cipher that provide security on attackers that see something between computations.
## Basic Definitions
![](https://i.imgur.com/u2JPFel.png)

Basics
- A communication takes place between two endpoints
	- sender: made of an information source and an encoder
	- receiver: made of an information destination and a dencoder
- Information is carried by a channel in the form of a sequence of symbols of a finite **alphabet**
## Transmitting and receiving
Losing uncertainty = Acquiring information
- The receiver gets information only through the channel
	 it will be uncertain on what the next symbol is, until the symbol arrives
	 thus we model the sender as a random variable
- Acquiring information is modeled as getting to know an outcome of a random variable X
	 the amount of information depends on the distribution of X
	 intuitively: the closer is X to a uniform distribution, the higher the amount of information I get from knowing an outcome
- Encoding maps each outcome as a finite sequence of symbols
	 More symbols should be needed when more information is sent
## Measuring uncertainty: Entropy
Desirable properties
- Non negative measure of uncertainty
- “combining uncertainties” should map to adding entropies
Definition
- Let X be a discrete r.v. with n outcomes in $\{x_0 , . . . , x_{n−1}\}$ with Pr(X = $x_i$ ) = $p_i$ for all 0 ⩽ i ⩽ n 
- The entropy of X is H(X) = $\sum_{i=0}^{n-1} −p_i log_b(p_i)$
- The measurement unit of entropy depends on the base b of the logarithm: typical case for b = 2 is bits
Pay attention on information stored in the word to guess and the symbols used to define it. 